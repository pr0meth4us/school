{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cfa05fc",
   "metadata": {},
   "source": [
    "# Lab: Supervised Learning\n",
    "\n",
    "### Objective: using the knowledge/techniques learnt during lectures to solve a facial recognition problem using scikit-learn. \n",
    "\n",
    "What will you learn: \n",
    "\n",
    "1. scikit-learn basics\n",
    "2. data processing/visualization\n",
    "3. model training\n",
    "4. model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da649191",
   "metadata": {},
   "source": [
    "## Task 1: learn scikit-learn basics\n",
    "\n",
    "Follow this [tuturial](https://scikit-learn.org/stable/tutorial/basic/tutorial.html) to learn the basics of \n",
    "scikit-learn. Make sure you install scikit learn properly and you work on Jupyter Lab environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e006935",
   "metadata": {},
   "source": [
    "## What is facial recognition ?\n",
    "\n",
    "Face recognition is the task of comparing an unknown individual’s face to images in a database of stored records. The mapping could be one–to–one or one–to–many, depending on whether we are running face verification or face identification.\n",
    "\n",
    "There are 4 main steps toward facial recognition: \n",
    "\n",
    "\n",
    "1. Detect faces in an image\n",
    "\n",
    "2. Crop & align faces for uniformity\n",
    "\n",
    "3. Find vector representation for each face\n",
    "\n",
    "Since programs can’t work with jpg or png files directly, we need some way of translating images to numbers. This can be done using state-of-the-art deep learning models such as InsightFace, ArcFace. However, to simplify the problem, we will be using a simple PCA (we will learn this in the next lecture) for this purpose. \n",
    "\n",
    "\n",
    "4. Comparing the embeddings\n",
    "\n",
    "Once we have translated each unique face into a vector, comparing faces essentials boils down to comparing the corresponding embeddings (a.k.a features vector). We will be making use of these embeddings to train a sci-kit learn model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce4dab",
   "metadata": {},
   "source": [
    "### Assumption\n",
    "\n",
    "To simplify the problem, we assume that all the faces have been detected and cropped. We will work on the 3rd and 4th points only. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a8892",
   "metadata": {},
   "source": [
    "## Task 2: loading and preprocessing \n",
    "\n",
    "We will use lfw (Labeled Face in the Wild) dataset for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d373acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size:\n",
      "n_samples: 1288\n",
      "n_features (50*37): 1850\n",
      "n_classes: 7\n",
      "all the people names in the datset: ['Ariel Sharon' 'Colin Powell' 'Donald Rumsfeld' 'George W Bush'\n",
      " 'Gerhard Schroeder' 'Hugo Chavez' 'Tony Blair']\n",
      "shape of image data: (1288, 50, 37)\n"
     ]
    }
   ],
   "source": [
    "# Loading lfw dataset\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "# introspect the images arrays to find the shapes (for plotting)\n",
    "n_samples, h, w = lfw_people.images.shape\n",
    "\n",
    "# for machine learning we use the 2 data directly (as relative pixel\n",
    "# positions info is ignored by this model)\n",
    "X = lfw_people.data\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "\n",
    "print(\"Total dataset size:\")\n",
    "print(\"n_samples: %d\" % n_samples)\n",
    "print(\"n_features (50*37): %d\" % n_features)\n",
    "print(\"n_classes: %d\" % n_classes)\n",
    "print(\"all the people names in the datset: %s\"% target_names)\n",
    "print(\"shape of image data:\", lfw_people.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a90a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot images with target name\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# The codes below show how to use matplotlib to plot two images (1 row and 2 columns)\n",
    "\n",
    "random_image = np.random.rand(255, 255)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "imgplot = plt.imshow(random_image)\n",
    "ax.set_title('Before')\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "imgplot = plt.imshow(random_image)\n",
    "imgplot.set_clim(0.0, 0.7)\n",
    "ax.set_title('After')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c4dcb3",
   "metadata": {},
   "source": [
    "Now adapt the above code to plot the images in lfw dataset. Your plot should contains: \n",
    "\n",
    "1. 7 rows (7 different people). \n",
    "2. each row has 5 images (columns) coming from the same person\n",
    "\n",
    "Hints:\n",
    "\n",
    "1. when showing big plot, use figsize to adapt the plot size. \n",
    "2. subplot index starts from 1, not 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4887d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1effe2ea",
   "metadata": {},
   "source": [
    "Split data into train, test set\n",
    "\n",
    "\n",
    "1. use train_test_split from scikit learn package to split the data (X, y) into 80% training, 20% testing\n",
    "2. What are the utilities of \"random_state\" and why should we use it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e13bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66585f",
   "metadata": {},
   "source": [
    "Data should be standardized (0 mean and 1 variance)\n",
    "\n",
    "1. Use StandardScaler from scikit learn package to transform data into 0 mean and 1 variance\n",
    "2. Explain why this is necessary\n",
    "\n",
    "Hint: do not forget to transform also the X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "964809ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a9de5",
   "metadata": {},
   "source": [
    "## Task 3: training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfaf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59f8b90b",
   "metadata": {},
   "source": [
    "Start training with decision tree.\n",
    "\n",
    "1. Read this article https://scikit-learn.org/stable/modules/tree.html\n",
    "2. Start training with decision tree\n",
    "3. Report performance using accuracy\n",
    "4. Visualize your tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff52890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb14b68",
   "metadata": {},
   "source": [
    "Start training with SVM\n",
    "\n",
    "1. Read this article https://scikit-learn.org/stable/modules/svm.html\n",
    "2. Start training with decision tree\n",
    "3. Report performance using accuracy\n",
    "4. Visualize your tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8037e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ad434",
   "metadata": {},
   "source": [
    "## Task 4 (optional, for the challengers)\n",
    "\n",
    "1. collect 100 photos and crop only the face\n",
    "2. add it to the dataset\n",
    "3. retrain your svm model\n",
    "4. use opencv (with webcame) to connect to your model\n",
    "5. try testing your new model in real time using your webcam\n",
    "\n",
    "Hint: https://realpython.com/face-detection-in-python-using-a-webcam/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6daee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
